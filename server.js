const express = require('express');
const cors = require('cors');
const { PDFNet } = require('@pdftron/pdfnet-node');
const pdfParse = require('pdf-parse');
const fs = require('fs');
const path = require('path');
const app = express();
const port = 3000;
const JSZip = require("jszip");
const { DOMParser, XMLSerializer } = require("xmldom");
// const mammoth = require("mammoth");

const allowCrossDomain = (req, res, next) => {
    res.header(`Access-Control-Allow-Origin`, `*`);
    res.header(`Access-Control-Allow-Methods`, `GET,PUT,POST,DELETE`);
    res.header(`Access-Control-Allow-Headers`, `Content-Type`);
    next();
};

app.use(allowCrossDomain);

app.use(express.static('public'));
app.use(cors({
    origin: '*',
}));

const upload = require('multer')({
    dest: 'uploads/'
});

// ----------------- Helper -----------------
async function modifyDocxDirectly(filePath, segments) {
    console.log(segments);
    
    try {
        // ƒê·ªçc file DOCX
        const data = fs.readFileSync(filePath);
        const zip = await JSZip.loadAsync(data);

        // ƒê·ªçc n·ªôi dung XML ch√≠nh
        const docXmlPath = "word/document.xml";
        const docXmlContent = await zip.file(docXmlPath).async("text");

        // Chuy·ªÉn XML th√†nh DOM
        const parser = new DOMParser();
        const xmlDoc = parser.parseFromString(docXmlContent, "text/xml");

        // T√¨m t·∫•t c·∫£ c√°c th·∫ª <w:t> (ch·ª©a n·ªôi dung vƒÉn b·∫£n)
        const textNodes = xmlDoc.getElementsByTagName("w:t");

        // G·ªôp to√†n b·ªô vƒÉn b·∫£n th√†nh m·ªôt chu·ªói ƒë·ªÉ t√¨m ki·∫øm
        let fullText = "";
        let textElements = [];
        
        for (let i = 0; i < textNodes.length; i++) {
            textElements.push({
                node: textNodes[i],
                text: textNodes[i].textContent
            });
            fullText += textNodes[i].textContent;
        }

        console.log(textElements);
        
        // Duy·ªát qua t·ª´ng ƒëo·∫°n c·∫ßn b√¥i v√†ng
        let searchStartIndex = 0; // Start searching from the beginning initially

        segments.forEach(({ segment }) => {
            let startIndex = fullText.indexOf(segment, searchStartIndex);
            if (startIndex !== -1) {
                console.log(`üîç T√¨m th·∫•y "${segment}" t·∫°i v·ªã tr√≠ ${startIndex}`);

                // T·∫°o th·∫ª highlight
                const highlightNode = xmlDoc.createElement("w:highlight");
                highlightNode.setAttribute("w:val", "yellow");

                // Ch√®n highlight v√†o c√°c th·∫ª <w:rPr> t∆∞∆°ng ·ª©ng
                let currentIndex = 0;
                for (let i = 0; i < textElements.length; i++) {
                    let { node, text } = textElements[i];

                    // N·∫øu ƒëo·∫°n vƒÉn b·∫£n n·∫±m trong kho·∫£ng c·∫ßn b√¥i v√†ng
                    if (
                        currentIndex >= startIndex &&
                        currentIndex < startIndex + segment.length
                    ) {
                        let parentRun = node.parentNode;
                        let rPrNode = xmlDoc.createElement("w:rPr");
                        rPrNode.appendChild(highlightNode.cloneNode(true));
                        parentRun.insertBefore(rPrNode, node);
                    }

                    currentIndex += text.length;
                }

                // Update the search start index to the end of the current segment
                searchStartIndex = startIndex + segment.length;
            } else {
                console.log("‚ùå C√°c ƒëo·∫°n sau kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu: \"", segment + "\"");
            }
        });

        // Chuy·ªÉn DOM v·ªÅ chu·ªói XML
        const serializer = new XMLSerializer();
        const newXml = serializer.serializeToString(xmlDoc);

        // Ghi l·∫°i n·ªôi dung m·ªõi v√†o ZIP
        zip.file(docXmlPath, newXml);

        // Ghi ƒë√® l·∫°i ch√≠nh file DOCX g·ªëc
        zip.generateAsync({ type: "nodebuffer" }).then((buffer) => {
            fs.writeFileSync(filePath, buffer);
            console.log("‚úÖ File DOCX ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t th√†nh c√¥ng!");
        });
    } catch (error) {
        console.error("‚ùå L·ªói khi ch·ªânh s·ª≠a file DOCX:", error);
    }
}

function guidGenerator() {
    var S4 = function() {
       return (((1+Math.random())*0x10000)|0).toString(16).substring(1);
    };
    return (S4()+S4()+"-"+S4()+"-"+S4()+"-"+S4()+"-"+S4()+S4()+S4());
}

async function extractTextFromPDF(pdfPath) {
    try {
        const dataBuffer = fs.readFileSync(pdfPath);
        const data = await pdfParse(dataBuffer);
        return data.text;
    } catch (error) {
        console.error("L·ªói khi ƒë·ªçc PDF:", error);
    }
}

async function extractTextFromDocx(docxPath) {
    try {
        const data = fs.readFileSync(docxPath);
        const zip = await JSZip.loadAsync(data);
        const contentXml = await zip.file("word/document.xml").async("text");
        const parser = new DOMParser();
        const xmlDoc = parser.parseFromString(contentXml, "text/xml");
        const textNodes = xmlDoc.getElementsByTagName("w:t");
        let text = "";
        for (let i = 0; i < textNodes.length; i++) {
            text += textNodes[i].textContent + " ";
        }
        return text;
    } catch (error) {
        console.error("L·ªói khi ƒë·ªçc DOCX:", error);
    }
}

function findAddedText(originalText, newText) {
    const originalWords = originalText.split(/\s+/); // T√°ch t·ª´ d·ª±a tr√™n kho·∫£ng tr·∫Øng
    const newWords = newText.split(/\s+/);
    console.log(originalWords);
    console.log(newWords);
    const dp = Array.from({ length: originalWords.length + 1 }, () => Array(newWords.length + 1).fill(0));

    // X√¢y d·ª±ng b·∫£ng DP cho LCS
    for (let i = 1; i <= originalWords.length; i++) {
        for (let j = 1; j <= newWords.length; j++) {
            if (originalWords[i - 1] === newWords[j - 1]) {
                dp[i][j] = dp[i - 1][j - 1] + 1;
            } else {
                dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);
            }
        }
    }

    // Truy v·∫øt ng∆∞·ª£c ƒë·ªÉ t√¨m c√°c ƒëo·∫°n ƒë∆∞·ª£c th√™m v√† v·ªã tr√≠ c·ªßa ch√∫ng
    let i = originalWords.length;
    let j = newWords.length;
    const addedSegments = [];

    let tempSegment = [];
    let tempOriginalIndexes = [];  // M·∫£ng ch·ª©a ch·ªâ m·ª•c trong `originalWords` cho t·ª´ ƒë∆∞·ª£c th√™m
    let tempNewIndexes = []; // M·∫£ng ch·ª©a ch·ªâ m·ª•c trong `newWords` cho t·ª´ ƒë∆∞·ª£c th√™m

    while (i > 0 || j > 0) {
        if (i > 0 && j > 0 && originalWords[i - 1] === newWords[j - 1]) {
            if (tempSegment.length > 0) {
                addedSegments.unshift({
                    segment: tempSegment.join(" "),
                    originalIndexes: tempOriginalIndexes,
                    newIndexes: tempNewIndexes
                });
                tempSegment = [];
                tempOriginalIndexes = [];
                tempNewIndexes = [];
            }
            i--;
            j--;
        } else if (j > 0 && (i === 0 || dp[i][j - 1] >= dp[i - 1][j])) {
            tempSegment.unshift(newWords[j - 1]); // Th√™m t·ª´ v√†o ƒëo·∫°n t·∫°m th·ªùi
            tempNewIndexes.unshift(j - 1); // L∆∞u ch·ªâ m·ª•c c·ªßa t·ª´ trong `newWords`
            j--;
        } else {
            i--;
        }
    }

    // N·∫øu c√≤n ƒëo·∫°n vƒÉn b·∫£n m·ªõi ch∆∞a ƒë∆∞·ª£c th√™m
    if (tempSegment.length > 0) {
        addedSegments.unshift({
            segment: tempSegment.join(" "),
            originalIndexes: [], // Kh√¥ng c√≥ ch·ªâ m·ª•c trong `originalWords` v√¨ ƒëo·∫°n n√†y ch·ªâ c√≥ trong vƒÉn b·∫£n m·ªõi
            newIndexes: tempNewIndexes
        });
    }

    return addedSegments;
}

// ---------------------------------------------------

// API to handle PDF upload
app.post('/convert', upload.fields([{ name: 'fileOrigin', maxCount: 1 }, { name: 'fileTranslation', maxCount: 1 }]), async (req, res) => {
    if (!req.files) {
        return res.status(400).send('No file uploaded.');
    }
    const pdfDir = path.join(__dirname, 'pdf');
    if (!fs.existsSync(pdfDir)) {
        fs.mkdirSync(pdfDir);
    }

    const fileTranslationNewPath = path.join(pdfDir, req.files.fileTranslation[0].filename) + ".pdf";
    fs.renameSync(req.files.fileTranslation[0].path, fileTranslationNewPath);
    req.files.fileTranslation[0].path = fileTranslationNewPath;
    
    const fileOriginPath = path.join(pdfDir, req.files.fileOrigin[0].filename) + ".pdf";
    fs.renameSync(req.files.fileOrigin[0].path, fileOriginPath);
    req.files.fileOrigin[0].path = fileOriginPath;

    const name = guidGenerator();
    const pathOrigin = path.join(__dirname, 'public') + '/' + name + '_origin.docx';
    const pathTranslation = path.join(__dirname, 'public') + '/' + name + '_translation.docx';
    await PDFNet.runWithCleanup(async () => {
        await PDFNet.addResourceSearchPath('./Lib/');
            // check if the module is available
            if (!(await PDFNet.StructuredOutputModule.isModuleAvailable())) {
                return;
            }
         
            await PDFNet.Convert.fileToWord(fileTranslationNewPath, pathTranslation);
            await PDFNet.Convert.fileToWord(fileOriginPath, pathOrigin);
        }, 'demo:1739949060645:617adfb903000000000935bcbf740717e9c6b2c11e6fd7ac9496321dc6')
            .catch(err => {
                console.error(err);
            })
            .then(async () => {
                PDFNet.shutdown();
                
                const originText = await extractTextFromDocx(pathOrigin);
                const translationText = await extractTextFromDocx(pathTranslation);
                const segments = findAddedText(originText, translationText);
                
                await modifyDocxDirectly(pathTranslation, segments);
                res.json({ message: 'File converted successfully', path: `${name}_translation.docx`, changed: segments });
            });
});

// API to convert DOCX to HTML
// app.post('/convert-docx-to-html', upload.single('file'), async (req, res) => {
//     if (!req.file) {
//         return res.status(400).send('No file uploaded.');
//     }

//     const docxFilePath = req.file.path;

//     try {
//         const result = await mammoth.convertToHtml({ path: docxFilePath });
//         res.send(result.value); // The generated HTML
//     } catch (error) {
//         console.error("Error converting DOCX to HTML:", error);
//         res.status(500).send('Error converting DOCX to HTML.');
//     } finally {
//         // Clean up the uploaded file
//         fs.unlinkSync(docxFilePath);
//     }
// });

app.listen(port, () => {
    console.log(`Server is running on port ${port}`);
});